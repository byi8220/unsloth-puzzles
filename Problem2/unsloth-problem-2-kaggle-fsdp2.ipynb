{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e5ce76",
   "metadata": {
    "papermill": {
     "duration": 0.003956,
     "end_time": "2025-04-10T05:08:01.196137",
     "exception": false,
     "start_time": "2025-04-10T05:08:01.192181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unsloth Problem 2 - Make `QLoRA` work with `FSDP2` \n",
    "\n",
    "This is the **Kaggle 2xT4** notebook, run for 60 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c40ba",
   "metadata": {
    "id": "uXshnajO44Kb",
    "papermill": {
     "duration": 0.002736,
     "end_time": "2025-04-10T05:08:01.201966",
     "exception": false,
     "start_time": "2025-04-10T05:08:01.199230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "<a name=\"FSDP2\"></a>\n",
    "## B) Make `QLoRA` work with `FSDP2` [Difficulty: Medium to Hard] [Max points: 10]\n",
    "\n",
    "1. Goal: Write a single Python script to finetune Llama 3.1 8B on 2x or more GPUs with FSDP2.\n",
    "\n",
    "2. You must showcase this working in a free **Kaggle notebook with 2 x Tesla T4 GPUs**.\n",
    "\n",
    "3. Pipeline parallelism is also fine, but must utilize [`zero bubble scheduling`](https://pytorch.org/docs/stable/distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble) somehow.\n",
    "\n",
    "4. Can use a pre-quantized 4bit BnB safetensor file from [Unsloth's HF page](https://huggingface.co/unsloth) or a full 16bit one, but must do QLoRA.\n",
    "\n",
    "5. Can use `accelerate` but must be FSDP2 or related - you can investigate https://github.com/huggingface/accelerate/pull/3394, Torch Titan, other repos etc.\n",
    "\n",
    "6. Must be fully `transformers` compatible - so we must use `TrainingArguments` and `Trainer`, or `TRL` related classes.\n",
    "\n",
    "7. The loss must be equivalent to single GPU training.\n",
    "\n",
    "8. You must enable all features in FSDP2 - ie showcase offloading, checkpointing, mixed precision training etc.\n",
    "\n",
    "9. You can use `nf4` from `torch AO`, but best from `bitsandbytes`.\n",
    "\n",
    "10. Finally showcase everything working in a free Kaggle 2x Tesla T4 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50aad710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:08:01.209868Z",
     "iopub.status.busy": "2025-04-10T05:08:01.209225Z",
     "iopub.status.idle": "2025-04-10T05:14:47.573575Z",
     "shell.execute_reply": "2025-04-10T05:14:47.572421Z"
    },
    "executionInfo": {
     "elapsed": 30396,
     "status": "ok",
     "timestamp": 1742414114585,
     "user": {
      "displayName": "Brian Yi",
      "userId": "16364797669375947161"
     },
     "user_tz": 240
    },
    "id": "F_rx9FYMOc2T",
    "papermill": {
     "duration": 406.369978,
     "end_time": "2025-04-10T05:14:47.575296",
     "exception": false,
     "start_time": "2025-04-10T05:08:01.205318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\r\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting huggingface_hub\r\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting hf_transfer\r\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting filelock (from datasets)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting numpy>=1.17 (from datasets)\r\n",
      "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets)\r\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting pandas (from datasets)\r\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting tqdm>=4.66.3 (from datasets)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m282.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess<0.70.17 (from datasets)\r\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting aiohttp (from datasets)\r\n",
      "  Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting packaging (from datasets)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pyyaml>=5.1 (from datasets)\r\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\r\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\r\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\r\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\r\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\r\n",
      "  Downloading multidict-6.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\r\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\r\n",
      "  Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m247.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets)\r\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets)\r\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\r\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\r\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\r\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\r\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m215.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m152.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m259.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m271.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m294.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m296.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m297.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m197.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m296.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m351.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m309.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m279.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m287.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m231.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m328.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m303.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m301.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m249.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multidict-6.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m322.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m325.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m298.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m310.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m304.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m189.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.7/358.7 kB\u001b[0m \u001b[31m343.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, typing-extensions, tqdm, six, pyyaml, pyarrow, propcache, packaging, numpy, multidict, idna, hf_transfer, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, multiprocess, aiosignal, pandas, huggingface_hub, aiohttp, datasets\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2025.2\r\n",
      "    Uninstalling pytz-2025.2:\r\n",
      "      Successfully uninstalled pytz-2025.2\r\n",
      "  Attempting uninstall: xxhash\r\n",
      "    Found existing installation: xxhash 3.5.0\r\n",
      "    Uninstalling xxhash-3.5.0:\r\n",
      "      Successfully uninstalled xxhash-3.5.0\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 2.3.0\r\n",
      "    Uninstalling urllib3-2.3.0:\r\n",
      "      Successfully uninstalled urllib3-2.3.0\r\n",
      "  Attempting uninstall: tzdata\r\n",
      "    Found existing installation: tzdata 2025.2\r\n",
      "    Uninstalling tzdata-2025.2:\r\n",
      "      Successfully uninstalled tzdata-2025.2\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.13.1\r\n",
      "    Uninstalling typing_extensions-4.13.1:\r\n",
      "      Successfully uninstalled typing_extensions-4.13.1\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.67.1\r\n",
      "    Uninstalling tqdm-4.67.1:\r\n",
      "      Successfully uninstalled tqdm-4.67.1\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.17.0\r\n",
      "    Uninstalling six-1.17.0:\r\n",
      "      Successfully uninstalled six-1.17.0\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0.2\r\n",
      "    Uninstalling PyYAML-6.0.2:\r\n",
      "      Successfully uninstalled PyYAML-6.0.2\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "  Attempting uninstall: propcache\r\n",
      "    Found existing installation: propcache 0.3.1\r\n",
      "    Uninstalling propcache-0.3.1:\r\n",
      "      Successfully uninstalled propcache-0.3.1\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 24.2\r\n",
      "    Uninstalling packaging-24.2:\r\n",
      "      Successfully uninstalled packaging-24.2\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: multidict\r\n",
      "    Found existing installation: multidict 6.2.0\r\n",
      "    Uninstalling multidict-6.2.0:\r\n",
      "      Successfully uninstalled multidict-6.2.0\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.10\r\n",
      "    Uninstalling idna-3.10:\r\n",
      "      Successfully uninstalled idna-3.10\r\n",
      "  Attempting uninstall: hf_transfer\r\n",
      "    Found existing installation: hf_transfer 0.1.9\r\n",
      "    Uninstalling hf_transfer-0.1.9:\r\n",
      "      Successfully uninstalled hf_transfer-0.1.9\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.3.2\r\n",
      "    Uninstalling fsspec-2025.3.2:\r\n",
      "      Successfully uninstalled fsspec-2025.3.2\r\n",
      "  Attempting uninstall: frozenlist\r\n",
      "    Found existing installation: frozenlist 1.5.0\r\n",
      "    Uninstalling frozenlist-1.5.0:\r\n",
      "      Successfully uninstalled frozenlist-1.5.0\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.18.0\r\n",
      "    Uninstalling filelock-3.18.0:\r\n",
      "      Successfully uninstalled filelock-3.18.0\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.8\r\n",
      "    Uninstalling dill-0.3.8:\r\n",
      "      Successfully uninstalled dill-0.3.8\r\n",
      "  Attempting uninstall: charset-normalizer\r\n",
      "    Found existing installation: charset-normalizer 3.4.1\r\n",
      "    Uninstalling charset-normalizer-3.4.1:\r\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2025.1.31\r\n",
      "    Uninstalling certifi-2025.1.31:\r\n",
      "      Successfully uninstalled certifi-2025.1.31\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 25.3.0\r\n",
      "    Uninstalling attrs-25.3.0:\r\n",
      "      Successfully uninstalled attrs-25.3.0\r\n",
      "  Attempting uninstall: aiohappyeyeballs\r\n",
      "    Found existing installation: aiohappyeyeballs 2.6.1\r\n",
      "    Uninstalling aiohappyeyeballs-2.6.1:\r\n",
      "      Successfully uninstalled aiohappyeyeballs-2.6.1\r\n",
      "  Attempting uninstall: yarl\r\n",
      "    Found existing installation: yarl 1.19.0\r\n",
      "    Uninstalling yarl-1.19.0:\r\n",
      "      Successfully uninstalled yarl-1.19.0\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.32.3\r\n",
      "    Uninstalling requests-2.32.3:\r\n",
      "      Successfully uninstalled requests-2.32.3\r\n",
      "  Attempting uninstall: python-dateutil\r\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\r\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\r\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\r\n",
      "  Attempting uninstall: multiprocess\r\n",
      "    Found existing installation: multiprocess 0.70.16\r\n",
      "    Uninstalling multiprocess-0.70.16:\r\n",
      "      Successfully uninstalled multiprocess-0.70.16\r\n",
      "  Attempting uninstall: aiosignal\r\n",
      "    Found existing installation: aiosignal 1.3.2\r\n",
      "    Uninstalling aiosignal-1.3.2:\r\n",
      "      Successfully uninstalled aiosignal-1.3.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.30.2\r\n",
      "    Uninstalling huggingface-hub-0.30.2:\r\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\r\n",
      "  Attempting uninstall: aiohttp\r\n",
      "    Found existing installation: aiohttp 3.11.16\r\n",
      "    Uninstalling aiohttp-3.11.16:\r\n",
      "      Successfully uninstalled aiohttp-3.11.16\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 3.5.0\r\n",
      "    Uninstalling datasets-3.5.0:\r\n",
      "      Successfully uninstalled datasets-3.5.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\r\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "matplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.2.4 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.4 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\r\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.2.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.5.0 fsspec-2024.12.0 hf_transfer-0.1.9 huggingface_hub-0.30.2 idna-3.10 multidict-6.4.2 multiprocess-0.70.16 numpy-2.2.4 packaging-24.2 pandas-2.2.3 propcache-0.3.1 pyarrow-19.0.1 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 six-1.17.0 tqdm-4.67.1 typing-extensions-4.13.1 tzdata-2025.2 urllib3-2.3.0 xxhash-3.5.0 yarl-1.19.0\r\n",
      "Collecting bitsandbytes\r\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\r\n",
      "Collecting peft\r\n",
      "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting trl\r\n",
      "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting matplotlib\r\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting torch<3,>=2.0 (from bitsandbytes)\r\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\r\n",
      "Collecting numpy>=1.17 (from bitsandbytes)\r\n",
      "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting packaging>=20.0 (from peft)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting psutil (from peft)\r\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting pyyaml (from peft)\r\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\r\n",
      "Collecting transformers (from peft)\r\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\r\n",
      "Collecting tqdm (from peft)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m234.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting accelerate>=0.21.0 (from peft)\r\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting safetensors (from peft)\r\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\r\n",
      "Collecting huggingface_hub>=0.25.0 (from peft)\r\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting datasets>=3.0.0 (from trl)\r\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting rich (from trl)\r\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\r\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\r\n",
      "Collecting pillow>=8 (from matplotlib)\r\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\r\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\r\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting filelock (from datasets>=3.0.0->trl)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->trl)\r\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\r\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting pandas (from datasets>=3.0.0->trl)\r\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m287.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests>=2.32.2 (from datasets>=3.0.0->trl)\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting xxhash (from datasets>=3.0.0->trl)\r\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\r\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl)\r\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting aiohttp (from datasets>=3.0.0->trl)\r\n",
      "  Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.25.0->peft)\r\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\r\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting networkx (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting jinja2 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting triton==3.2.0 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting sympy==1.13.1 (from torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting regex!=2019.12.17 (from transformers->peft)\r\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m203.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers->peft)\r\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl)\r\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->trl)\r\n",
      "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading multidict-6.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=3.0.0->trl)\r\n",
      "  Downloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\r\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets>=3.0.0->trl)\r\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\r\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets>=3.0.0->trl)\r\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets>=3.0.0->trl)\r\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets>=3.0.0->trl)\r\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch<3,>=2.0->bitsandbytes)\r\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=3.0.0->trl)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=3.0.0->trl)\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m303.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading peft-0.15.1-py3-none-any.whl (411 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m336.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading trl-0.16.1-py3-none-any.whl (336 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m280.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m302.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m301.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m247.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m315.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m300.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m302.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m296.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m295.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m282.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m324.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m308.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m335.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m341.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m331.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m299.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m301.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m271.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m307.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m308.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m257.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m268.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m184.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m262.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m260.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m275.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m295.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m291.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m219.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m262.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m197.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m300.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading transformers-4.51.1-py3-none-any.whl (10.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m288.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m304.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m273.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m292.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m297.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m304.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m254.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m320.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m224.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m236.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m316.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m264.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m217.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m268.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m251.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m233.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m327.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m239.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m295.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m181.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m275.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m274.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\r\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m237.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading multidict-6.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.5/232.5 kB\u001b[0m \u001b[31m275.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m301.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m160.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m164.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yarl-1.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.7/358.7 kB\u001b[0m \u001b[31m155.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, xxhash, urllib3, tzdata, typing-extensions, tqdm, sympy, six, safetensors, regex, pyyaml, pyparsing, pygments, pyarrow, psutil, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, kiwisolver, idna, fsspec, frozenlist, fonttools, filelock, dill, cycler, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jinja2, contourpy, aiosignal, rich, pandas, nvidia-cusolver-cu12, matplotlib, huggingface_hub, aiohttp, torch, tokenizers, transformers, datasets, bitsandbytes, accelerate, trl, peft\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.1.0\r\n",
      "    Uninstalling triton-3.1.0:\r\n",
      "      Successfully uninstalled triton-3.1.0\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2025.2\r\n",
      "    Uninstalling pytz-2025.2:\r\n",
      "      Successfully uninstalled pytz-2025.2\r\n",
      "  Attempting uninstall: mpmath\r\n",
      "    Found existing installation: mpmath 1.3.0\r\n",
      "    Uninstalling mpmath-1.3.0:\r\n",
      "      Successfully uninstalled mpmath-1.3.0\r\n",
      "  Attempting uninstall: xxhash\r\n",
      "    Found existing installation: xxhash 3.5.0\r\n",
      "    Uninstalling xxhash-3.5.0:\r\n",
      "      Successfully uninstalled xxhash-3.5.0\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 2.3.0\r\n",
      "    Uninstalling urllib3-2.3.0:\r\n",
      "      Successfully uninstalled urllib3-2.3.0\r\n",
      "  Attempting uninstall: tzdata\r\n",
      "    Found existing installation: tzdata 2025.2\r\n",
      "    Uninstalling tzdata-2025.2:\r\n",
      "      Successfully uninstalled tzdata-2025.2\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.13.1\r\n",
      "    Uninstalling typing_extensions-4.13.1:\r\n",
      "      Successfully uninstalled typing_extensions-4.13.1\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.67.1\r\n",
      "    Uninstalling tqdm-4.67.1:\r\n",
      "      Successfully uninstalled tqdm-4.67.1\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.17.0\r\n",
      "    Uninstalling six-1.17.0:\r\n",
      "      Successfully uninstalled six-1.17.0\r\n",
      "  Attempting uninstall: safetensors\r\n",
      "    Found existing installation: safetensors 0.5.2\r\n",
      "    Uninstalling safetensors-0.5.2:\r\n",
      "      Successfully uninstalled safetensors-0.5.2\r\n",
      "  Attempting uninstall: regex\r\n",
      "    Found existing installation: regex 2024.11.6\r\n",
      "    Uninstalling regex-2024.11.6:\r\n",
      "      Successfully uninstalled regex-2024.11.6\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0.2\r\n",
      "    Uninstalling PyYAML-6.0.2:\r\n",
      "      Successfully uninstalled PyYAML-6.0.2\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.2.1\r\n",
      "    Uninstalling pyparsing-3.2.1:\r\n",
      "      Successfully uninstalled pyparsing-3.2.1\r\n",
      "  Attempting uninstall: pygments\r\n",
      "    Found existing installation: Pygments 2.19.1\r\n",
      "    Uninstalling Pygments-2.19.1:\r\n",
      "      Successfully uninstalled Pygments-2.19.1\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 7.0.0\r\n",
      "    Uninstalling psutil-7.0.0:\r\n",
      "      Successfully uninstalled psutil-7.0.0\r\n",
      "  Attempting uninstall: propcache\r\n",
      "    Found existing installation: propcache 0.3.1\r\n",
      "    Uninstalling propcache-0.3.1:\r\n",
      "      Successfully uninstalled propcache-0.3.1\r\n",
      "  Attempting uninstall: pillow\r\n",
      "    Found existing installation: pillow 11.1.0\r\n",
      "    Uninstalling pillow-11.1.0:\r\n",
      "      Successfully uninstalled pillow-11.1.0\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 24.2\r\n",
      "    Uninstalling packaging-24.2:\r\n",
      "      Successfully uninstalled packaging-24.2\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.2.4\r\n",
      "    Uninstalling numpy-2.2.4:\r\n",
      "      Successfully uninstalled numpy-2.2.4\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.4.2\r\n",
      "    Uninstalling networkx-3.4.2:\r\n",
      "      Successfully uninstalled networkx-3.4.2\r\n",
      "  Attempting uninstall: multidict\r\n",
      "    Found existing installation: multidict 6.4.2\r\n",
      "    Uninstalling multidict-6.4.2:\r\n",
      "      Successfully uninstalled multidict-6.4.2\r\n",
      "  Attempting uninstall: mdurl\r\n",
      "    Found existing installation: mdurl 0.1.2\r\n",
      "    Uninstalling mdurl-0.1.2:\r\n",
      "      Successfully uninstalled mdurl-0.1.2\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 3.0.2\r\n",
      "    Uninstalling MarkupSafe-3.0.2:\r\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\r\n",
      "  Attempting uninstall: kiwisolver\r\n",
      "    Found existing installation: kiwisolver 1.4.8\r\n",
      "    Uninstalling kiwisolver-1.4.8:\r\n",
      "      Successfully uninstalled kiwisolver-1.4.8\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.10\r\n",
      "    Uninstalling idna-3.10:\r\n",
      "      Successfully uninstalled idna-3.10\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2024.12.0\r\n",
      "    Uninstalling fsspec-2024.12.0:\r\n",
      "      Successfully uninstalled fsspec-2024.12.0\r\n",
      "  Attempting uninstall: frozenlist\r\n",
      "    Found existing installation: frozenlist 1.5.0\r\n",
      "    Uninstalling frozenlist-1.5.0:\r\n",
      "      Successfully uninstalled frozenlist-1.5.0\r\n",
      "  Attempting uninstall: fonttools\r\n",
      "    Found existing installation: fonttools 4.56.0\r\n",
      "    Uninstalling fonttools-4.56.0:\r\n",
      "      Successfully uninstalled fonttools-4.56.0\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.18.0\r\n",
      "    Uninstalling filelock-3.18.0:\r\n",
      "      Successfully uninstalled filelock-3.18.0\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.8\r\n",
      "    Uninstalling dill-0.3.8:\r\n",
      "      Successfully uninstalled dill-0.3.8\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: charset-normalizer\r\n",
      "    Found existing installation: charset-normalizer 3.4.1\r\n",
      "    Uninstalling charset-normalizer-3.4.1:\r\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2025.1.31\r\n",
      "    Uninstalling certifi-2025.1.31:\r\n",
      "      Successfully uninstalled certifi-2025.1.31\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 25.3.0\r\n",
      "    Uninstalling attrs-25.3.0:\r\n",
      "      Successfully uninstalled attrs-25.3.0\r\n",
      "  Attempting uninstall: aiohappyeyeballs\r\n",
      "    Found existing installation: aiohappyeyeballs 2.6.1\r\n",
      "    Uninstalling aiohappyeyeballs-2.6.1:\r\n",
      "      Successfully uninstalled aiohappyeyeballs-2.6.1\r\n",
      "  Attempting uninstall: yarl\r\n",
      "    Found existing installation: yarl 1.19.0\r\n",
      "    Uninstalling yarl-1.19.0:\r\n",
      "      Successfully uninstalled yarl-1.19.0\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.32.3\r\n",
      "    Uninstalling requests-2.32.3:\r\n",
      "      Successfully uninstalled requests-2.32.3\r\n",
      "  Attempting uninstall: python-dateutil\r\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\r\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\r\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: multiprocess\r\n",
      "    Found existing installation: multiprocess 0.70.16\r\n",
      "    Uninstalling multiprocess-0.70.16:\r\n",
      "      Successfully uninstalled multiprocess-0.70.16\r\n",
      "  Attempting uninstall: markdown-it-py\r\n",
      "    Found existing installation: markdown-it-py 3.0.0\r\n",
      "    Uninstalling markdown-it-py-3.0.0:\r\n",
      "      Successfully uninstalled markdown-it-py-3.0.0\r\n",
      "  Attempting uninstall: jinja2\r\n",
      "    Found existing installation: Jinja2 3.1.6\r\n",
      "    Uninstalling Jinja2-3.1.6:\r\n",
      "      Successfully uninstalled Jinja2-3.1.6\r\n",
      "  Attempting uninstall: contourpy\r\n",
      "    Found existing installation: contourpy 1.3.1\r\n",
      "    Uninstalling contourpy-1.3.1:\r\n",
      "      Successfully uninstalled contourpy-1.3.1\r\n",
      "  Attempting uninstall: aiosignal\r\n",
      "    Found existing installation: aiosignal 1.3.2\r\n",
      "    Uninstalling aiosignal-1.3.2:\r\n",
      "      Successfully uninstalled aiosignal-1.3.2\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 14.0.0\r\n",
      "    Uninstalling rich-14.0.0:\r\n",
      "      Successfully uninstalled rich-14.0.0\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.7.5\r\n",
      "    Uninstalling matplotlib-3.7.5:\r\n",
      "      Successfully uninstalled matplotlib-3.7.5\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.30.2\r\n",
      "    Uninstalling huggingface-hub-0.30.2:\r\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\r\n",
      "  Attempting uninstall: aiohttp\r\n",
      "    Found existing installation: aiohttp 3.11.16\r\n",
      "    Uninstalling aiohttp-3.11.16:\r\n",
      "      Successfully uninstalled aiohttp-3.11.16\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.5.1+cu124\r\n",
      "    Uninstalling torch-2.5.1+cu124:\r\n",
      "      Successfully uninstalled torch-2.5.1+cu124\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.21.0\r\n",
      "    Uninstalling tokenizers-0.21.0:\r\n",
      "      Successfully uninstalled tokenizers-0.21.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.51.1\r\n",
      "    Uninstalling transformers-4.51.1:\r\n",
      "      Successfully uninstalled transformers-4.51.1\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 3.5.0\r\n",
      "    Uninstalling datasets-3.5.0:\r\n",
      "      Successfully uninstalled datasets-3.5.0\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 1.3.0\r\n",
      "    Uninstalling accelerate-1.3.0:\r\n",
      "      Successfully uninstalled accelerate-1.3.0\r\n",
      "  Attempting uninstall: peft\r\n",
      "    Found existing installation: peft 0.14.0\r\n",
      "    Uninstalling peft-0.14.0:\r\n",
      "      Successfully uninstalled peft-0.14.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.4 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\r\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.4 which is incompatible.\r\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.2.4 which is incompatible.\r\n",
      "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\r\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 accelerate-1.6.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 attrs-25.3.0 bitsandbytes-0.45.5 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.1 cycler-0.12.1 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 fonttools-4.57.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface_hub-0.30.2 idna-3.10 jinja2-3.1.6 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 mpmath-1.3.0 multidict-6.4.2 multiprocess-0.70.16 networkx-3.4.2 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 packaging-24.2 pandas-2.2.3 peft-0.15.1 pillow-11.1.0 propcache-0.3.1 psutil-7.0.0 pyarrow-19.0.1 pygments-2.19.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 rich-14.0.0 safetensors-0.5.3 six-1.17.0 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.51.1 triton-3.2.0 trl-0.16.1 typing-extensions-4.13.1 tzdata-2025.2 urllib3-2.3.0 xxhash-3.5.0 yarl-1.19.0\r\n",
      "Collecting git+https://github.com/byi8220/accelerate.git@experimental/qlora-fsdp2\r\n",
      "  Cloning https://github.com/byi8220/accelerate.git (to revision experimental/qlora-fsdp2) to /tmp/pip-req-build-wtsrzbjg\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/byi8220/accelerate.git /tmp/pip-req-build-wtsrzbjg\r\n",
      "  Running command git checkout -b experimental/qlora-fsdp2 --track origin/experimental/qlora-fsdp2\r\n",
      "  Switched to a new branch 'experimental/qlora-fsdp2'\r\n",
      "  Branch 'experimental/qlora-fsdp2' set up to track remote branch 'experimental/qlora-fsdp2' from 'origin'.\r\n",
      "  Resolved https://github.com/byi8220/accelerate.git to commit 70b8e7139f09583544ace743596ed2a970ffa8f4\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (2.2.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (24.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (6.0.2)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (2.6.0)\r\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (0.30.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.7.0.dev0) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2024.12.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (4.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.1.6)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.7.0.dev0) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.7.0.dev0) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.7.0.dev0) (3.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.7.0.dev0) (2025.1.31)\r\n",
      "Building wheels for collected packages: accelerate\r\n",
      "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for accelerate: filename=accelerate-1.7.0.dev0-py3-none-any.whl size=355045 sha256=e9d2520931ebaeb346dba11e100a3f37523a2286daeb258e972c32421f1e95bb\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lmf9be9b/wheels/32/6b/8e/34d12054ac7fdced8b2e60a3c1177e3030bb443b4b9b81fc65\r\n",
      "Successfully built accelerate\r\n",
      "Installing collected packages: accelerate\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 1.6.0\r\n",
      "    Uninstalling accelerate-1.6.0:\r\n",
      "      Successfully uninstalled accelerate-1.6.0\r\n",
      "Successfully installed accelerate-1.7.0.dev0\r\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\r\n",
      "Collecting torch\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\r\n",
      "Collecting torchaudio\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting filelock (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting sympy==1.13.1 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting networkx (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting jinja2 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting fsspec (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m297.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.6.77 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting triton==3.2.0 (from torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m338.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy (from torchvision)\r\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\r\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\r\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\r\n",
      "Downloading https://download.pytorch.org/whl/cu126/torch-2.6.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (764.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.6/764.6 MB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m230.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.whl (8.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m217.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m229.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (897 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m284.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m240.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.whl (200.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m256.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m236.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.whl (158.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m233.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.whl (216.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m294.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m292.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (89 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m227.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m244.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchvision-0.21.0%2Bcu126-cp311-cp311-linux_x86_64.whl (7.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m181.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl (3.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m201.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m208.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\r\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m147.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m157.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m246.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m230.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\r\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\r\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\r\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\r\n",
      "  Attempting uninstall: mpmath\r\n",
      "    Found existing installation: mpmath 1.3.0\r\n",
      "    Uninstalling mpmath-1.3.0:\r\n",
      "      Successfully uninstalled mpmath-1.3.0\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.13.1\r\n",
      "    Uninstalling typing_extensions-4.13.1:\r\n",
      "      Successfully uninstalled typing_extensions-4.13.1\r\n",
      "  Attempting uninstall: sympy\r\n",
      "    Found existing installation: sympy 1.13.1\r\n",
      "    Uninstalling sympy-1.13.1:\r\n",
      "      Successfully uninstalled sympy-1.13.1\r\n",
      "  Attempting uninstall: pillow\r\n",
      "    Found existing installation: pillow 11.1.0\r\n",
      "    Uninstalling pillow-11.1.0:\r\n",
      "      Successfully uninstalled pillow-11.1.0\r\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\r\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-nccl-cu12\r\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\r\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\r\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.2.4\r\n",
      "    Uninstalling numpy-2.2.4:\r\n",
      "      Successfully uninstalled numpy-2.2.4\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.4.2\r\n",
      "    Uninstalling networkx-3.4.2:\r\n",
      "      Successfully uninstalled networkx-3.4.2\r\n",
      "  Attempting uninstall: MarkupSafe\r\n",
      "    Found existing installation: MarkupSafe 3.0.2\r\n",
      "    Uninstalling MarkupSafe-3.0.2:\r\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2024.12.0\r\n",
      "    Uninstalling fsspec-2024.12.0:\r\n",
      "      Successfully uninstalled fsspec-2024.12.0\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.18.0\r\n",
      "    Uninstalling filelock-3.18.0:\r\n",
      "      Successfully uninstalled filelock-3.18.0\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\r\n",
      "  Attempting uninstall: jinja2\r\n",
      "    Found existing installation: Jinja2 3.1.6\r\n",
      "    Uninstalling Jinja2-3.1.6:\r\n",
      "      Successfully uninstalled Jinja2-3.1.6\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0\r\n",
      "    Uninstalling torch-2.6.0:\r\n",
      "      Successfully uninstalled torch-2.6.0\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.20.1+cu124\r\n",
      "    Uninstalling torchvision-0.20.1+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.20.1+cu124\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.5.1+cu124\r\n",
      "    Uninstalling torchaudio-2.5.1+cu124:\r\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.2 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.2 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.1.2 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\r\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\r\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.1.2 which is incompatible.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.2 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.2 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\r\n",
      "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.1.2 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 2.1.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu126 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cu126 torchaudio-2.6.0+cu126 torchvision-0.21.0+cu126 triton-3.2.0 typing-extensions-4.12.2\r\n",
      "Collecting numpy==1.26.1\r\n",
      "  Downloading numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m266.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.1.2\r\n",
      "    Uninstalling numpy-2.1.2:\r\n",
      "      Successfully uninstalled numpy-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.1 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.1 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.26.1 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "langchain 0.3.18 requires numpy<2,>=1.26.4; python_version < \"3.12\", but you have numpy 1.26.1 which is incompatible.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu126 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.26.1\r\n",
      "Collecting git+https://github.com/huggingface/transformers.git\r\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-7q0hj9ps\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-7q0hj9ps\r\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 9cda4265d61b0ecc276b705bd9b361a452106128\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (1.26.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.1.31)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11226167 sha256=a7cd3577ebd060386fb5a13bbbd6e0d61ef775c5d488e2afbbcb360bef059455\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-riup9rvp/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.51.1\r\n",
      "    Uninstalling transformers-4.51.1:\r\n",
      "      Successfully uninstalled transformers-4.51.1\r\n",
      "Successfully installed transformers-4.52.0.dev0\r\n",
      "Collecting scipy==1.11.2\r\n",
      "  Downloading scipy-1.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy<1.28.0,>=1.21.6 (from scipy==1.11.2)\r\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m278.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading scipy-1.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m267.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m299.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.1\r\n",
      "    Uninstalling numpy-1.26.1:\r\n",
      "      Successfully uninstalled numpy-1.26.1\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.15.2\r\n",
      "    Uninstalling scipy-1.15.2:\r\n",
      "      Successfully uninstalled scipy-1.15.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.2 which is incompatible.\r\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\r\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu126 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.11.2\r\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (8.1.5)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (4.0.13)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\r\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n"
     ]
    }
   ],
   "source": [
    "# Code to install Unsloth, Triton, Torch etc\n",
    "\n",
    "# For FSDP2 we need torch >= 2.6.0 (Many version incompatabilities, but we can hack something together)\n",
    "# NOTE: Many sources suggest FSDP2 is supported as of torch>=2.5.1, but it may have been experimental then?\n",
    "!pip install --no-cache-dir --force-reinstall datasets huggingface_hub hf_transfer\n",
    "!pip install --no-cache-dir --force-reinstall bitsandbytes peft trl matplotlib\n",
    "\n",
    "# Need some changes to `accelerate` to support FSDP2 in accelerate\n",
    "!pip install --no-cache-dir git+https://github.com/byi8220/accelerate.git@experimental/qlora-fsdp2\n",
    "\n",
    "# Torch 2.6.0 for FSDP2\n",
    "!pip install --no-cache-dir --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# Upgrading torch leads to version breakages relating to numpy, transformers, scipy\n",
    "# https://github.com/scipy/scipy/issues/21014\n",
    "!pip install --no-cache-dir --force-reinstall numpy==1.26.1\n",
    "\n",
    "# Install from head to get access to https://github.com/huggingface/transformers/pull/37147\n",
    "!pip install --no-cache-dir git+https://github.com/huggingface/transformers.git \n",
    "!pip install --no-cache-dir --force-reinstall scipy==1.11.2\n",
    "\n",
    "!pip install ipywidgets # Needed to export to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5324a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:14:47.683371Z",
     "iopub.status.busy": "2025-04-10T05:14:47.682619Z",
     "iopub.status.idle": "2025-04-10T05:14:47.687256Z",
     "shell.execute_reply": "2025-04-10T05:14:47.686756Z"
    },
    "papermill": {
     "duration": 0.057858,
     "end_time": "2025-04-10T05:14:47.688367",
     "exception": false,
     "start_time": "2025-04-10T05:14:47.630509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We must set env vars before importing torch\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,\"\\\n",
    "    \"roundup_power2_divisions:[32:256,64:128,256:64,>:32]\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0680d5f",
   "metadata": {
    "papermill": {
     "duration": 0.04731,
     "end_time": "2025-04-10T05:14:47.783297",
     "exception": false,
     "start_time": "2025-04-10T05:14:47.735987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FSDP2 Enabled Model\n",
    "We are launching the script in https://www.kaggle.com/code/byi8220/fsdp2-qlora-py/notebook via `accelerate`.\n",
    "\n",
    "The choice to use `accelerate` stems from the requirement that the solution \"Must be fully `transformers` compatible - so we must use `TrainingArguments` and `Trainer`, or `TRL` related classes.\"\n",
    "\n",
    "Since `TRL` uses an `accelerator` under the hood (see [TRL docs](https://github.com/huggingface/trl/blob/main/docs/source/distributing_training.md)), the least invasive option appears to be to interop with `accelerate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fe45de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:14:47.885132Z",
     "iopub.status.busy": "2025-04-10T05:14:47.884581Z",
     "iopub.status.idle": "2025-04-10T05:14:47.890311Z",
     "shell.execute_reply": "2025-04-10T05:14:47.889626Z"
    },
    "papermill": {
     "duration": 0.057057,
     "end_time": "2025-04-10T05:14:47.891379",
     "exception": false,
     "start_time": "2025-04-10T05:14:47.834322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fsdp_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile fsdp_config.yaml\n",
    "# Since we are doing FSDP (even though it's multi-GPU), we need to specify the distributed type as FSDP\n",
    "distributed_type: FSDP\n",
    "# Can be one of \"no\", \"fp16\", or \"bf16\" (see `transformer_engine.yaml` for `fp8`, but it works for FSDP as well)\n",
    "mixed_precision: 'fp16'\n",
    "# Specify the number of GPUs to use\n",
    "num_processes: 2\n",
    "# Then we can specify the FSDP config\n",
    "fsdp_config:\n",
    "  fsdp_activation_checkpointing: true\n",
    "  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP\n",
    "  fsdp_backward_prefetch: BACKWARD_PRE\n",
    "  fsdp_cpu_ram_efficient_loading: true # Required for Qlora https://github.com/huggingface/accelerate/issues/1620\n",
    "  fsdp_forward_prefetch: false\n",
    "  fsdp_offload_params: false\n",
    "  fsdp_sharding_strategy: FULL_SHARD\n",
    "  fsdp_state_dict_type: SHARDED_STATE_DICT\n",
    "  fsdp_sync_module_states: true\n",
    "  fsdp_use_orig_params: true\n",
    "  # fsdp_version: 2 # We are converting from fsdp1->fsdp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcb620",
   "metadata": {
    "papermill": {
     "duration": 0.048184,
     "end_time": "2025-04-10T05:14:47.988307",
     "exception": false,
     "start_time": "2025-04-10T05:14:47.940123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Porting Params4Bit tensors into a DTensor\n",
    "\n",
    "FSDP2 handles parameter sharding by converting ordinary tensors into `DTensor` objects. DTensors are a *Tensor Parallel* abstraction, where an individual tensor\n",
    "is partitioned into shards.\n",
    "\n",
    "From the docstring for `fully_shard`:\n",
    "```\n",
    "    At initialization, FSDP shards the module's parameters across the data\n",
    "    parallel workers given by ``mesh``. Before forward, FSDP all-gathers the\n",
    "    sharded parameters across the data-parallel workers to get the unsharded\n",
    "    parameters for forward computation. If ``reshard_after_forward`` is\n",
    "    ``True``, then FSDP frees the unsharded parameters after forward and\n",
    "    re-all-gathers them in backward before gradient computation.\n",
    "```\n",
    "In other words, for any worker, its parameters live in distributed space, however is fully colocated for any computation. This means that in theory, we can\n",
    "dequantize and then matmul using a quantized parameter by letting FSDP2 be responsible for materializing the full tensor beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc6bc1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:14:48.089445Z",
     "iopub.status.busy": "2025-04-10T05:14:48.089013Z",
     "iopub.status.idle": "2025-04-10T05:14:48.100345Z",
     "shell.execute_reply": "2025-04-10T05:14:48.099749Z"
    },
    "papermill": {
     "duration": 0.063253,
     "end_time": "2025-04-10T05:14:48.101474",
     "exception": false,
     "start_time": "2025-04-10T05:14:48.038221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "# Get FSDP2 working\n",
    "# FSDP2 interface (https://pytorch.org/docs/stable/distributed.fsdp.fully_shard.html)\n",
    "\n",
    "# Patching huggingface repos is a mess. I needed to hack a patch into `Trainer._inner_training_loop`, which is not clean\n",
    "import os \n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed.fsdp import fully_shard, CPUOffloadPolicy, MixedPrecisionPolicy\n",
    "from torch.distributed.device_mesh import init_device_mesh\n",
    "from accelerate import notebook_launcher, FullyShardedDataParallelPlugin\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "import torch\n",
    "import time\n",
    "import transformers.trainer\n",
    "from bitsandbytes.nn.modules import Linear4bit as bnb_Linear4bit\n",
    "from peft.tuners.lora.bnb import Linear4bit as peft_Linear4bit\n",
    "\n",
    "# FSDP2 shards parameters across devices, which interferes with quantized parameters.\n",
    "# The naive solution to this problem is to not shard quantized parameters across multiple GPUs\n",
    "def patch_fsdp():\n",
    "    from torch.distributed.fsdp._fully_shard._fsdp_param import FSDPParam\n",
    "    _init_dtype_attrs = FSDPParam.init_dtype_attrs\n",
    "\n",
    "    # Patch init_dtype_attrs to not cast quantized types to float\n",
    "    def _patched_init_dtype_attrs(self, mp_policy):\n",
    "        param_dtype, reduce_dtype = (mp_policy.param_dtype, mp_policy.reduce_dtype)\n",
    "        self.orig_dtype = self.sharded_param.dtype\n",
    "        # Clamp `param_dtype` to `None` if no casting is required\n",
    "        if param_dtype == self.orig_dtype:\n",
    "            param_dtype = None\n",
    "\n",
    "        # Quantized int types shouldn't be cast to float \n",
    "        int_types = [torch.uint8, torch.uint16, torch.uint32, torch.uint64]\n",
    "        if self.orig_dtype in int_types:\n",
    "            param_dtype = None\n",
    "            quant_dtype = self.orig_dtype\n",
    "\n",
    "        self.param_dtype = param_dtype\n",
    "        self.reduce_dtype = reduce_dtype\n",
    "        # None indicates that the mixed precision is not enabled\n",
    "\n",
    "\n",
    "    # Patch `init_sharded_param` to initialize sharded params without gradient.\n",
    "    # Tbh there is only a single line of diff between this and the baseline init_sharded_param. \n",
    "    # I raised a question in pytorch forums about this as well since it bothered me enough: https://discuss.pytorch.org/t/very-small-stupid-question-about-fsdpparam-init-sharded-param/218875\n",
    "    FSDPParam.init_dtype_attrs = _patched_init_dtype_attrs\n",
    "\n",
    "    # Include imports for patching.\n",
    "    import inspect\n",
    "    import itertools\n",
    "    from dataclasses import dataclass, field\n",
    "    from enum import auto, Enum\n",
    "    from typing import Any, Callable, cast, List, Optional, Sequence, Tuple\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch._prims_common import make_contiguous_strides_for\n",
    "    from torch.distributed._functional_collectives import AsyncCollectiveTensor\n",
    "    from torch.distributed.tensor import DTensor, Replicate, Shard\n",
    "    from torch.distributed.tensor._dtensor_spec import DTensorSpec, TensorMeta\n",
    "    from torch.distributed.tensor.device_mesh import _mesh_resources\n",
    "    from torch.distributed.tensor.placement_types import _StridedShard, Placement\n",
    "    from torch.distributed.fsdp._fully_shard._fsdp_api import CPUOffloadPolicy, MixedPrecisionPolicy, OffloadPolicy\n",
    "    from torch.distributed.fsdp._fully_shard._fsdp_common import (\n",
    "        _chunk_with_empty,\n",
    "        _from_local_no_grad,\n",
    "        _get_dim_chunked_size,\n",
    "        _raise_assert_with_print,\n",
    "        _to_dtype_if_needed,\n",
    "        compiled_autograd_enabled,\n",
    "        FSDPMeshInfo,\n",
    "        HSDPMeshInfo,\n",
    "    )\n",
    "    from torch.distributed.fsdp._fully_shard._fsdp_param import (\n",
    "        ShardedState,\n",
    "        ParamModuleInfo,\n",
    "        ExtensionsData,\n",
    "    )\n",
    "    @torch.no_grad()\n",
    "    def _patched_init_sharded_param(\n",
    "        self,\n",
    "        param: nn.Parameter,\n",
    "        device: torch.device,\n",
    "        shard_placement_fn: Optional[Callable],\n",
    "    ):\n",
    "        if param.device != device and param.device.type != \"meta\":\n",
    "            raise AssertionError(\n",
    "                f\"Expects the parameter to already be moved to device {device} but got {param.device}\"\n",
    "            )\n",
    "        if not param.is_contiguous():\n",
    "            raise NotImplementedError(\n",
    "                f\"FSDP does not support non-contiguous parameters yet: {param.shape=} {param.stride()=}\"\n",
    "            )\n",
    "        fsdp_placement = shard_placement_fn(param) if shard_placement_fn else None\n",
    "        if fsdp_placement is None:\n",
    "            fsdp_placement = Shard(0)\n",
    "        elif fsdp_placement.dim < 0:\n",
    "            fsdp_placement = Shard(fsdp_placement.dim + param.ndim)\n",
    "        assert isinstance(fsdp_placement, Shard), f\"{fsdp_placement}\"\n",
    "        self.fsdp_placement = fsdp_placement\n",
    "        shard_dim = fsdp_placement.dim\n",
    "        # TODO: Replace the sharded DTensor parameter construction logic with\n",
    "        # `distribute_tensor` after https://github.com/pytorch/pytorch/issues/116101\n",
    "        # TODO: Simplify the following sharded parameter padding logic after\n",
    "        # https://github.com/pytorch/pytorch/issues/113045\n",
    "        self.is_dtensor = isinstance(param, DTensor)\n",
    "        if self.is_dtensor:\n",
    "            self._tp_spec = cast(DTensor, param)._spec\n",
    "            dp_mesh, tp_mesh = (self.mesh_info.mesh, self._tp_spec.mesh)\n",
    "            dp_global_mesh = _mesh_resources.get_root_mesh(dp_mesh)\n",
    "            tp_global_mesh = _mesh_resources.get_root_mesh(tp_mesh)\n",
    "            if dp_global_mesh != tp_global_mesh or (\n",
    "                dp_global_mesh is None or tp_global_mesh is None\n",
    "            ):\n",
    "                raise AssertionError(\n",
    "                    \"FSDP requires the DP and TP mesh to have the same parent mesh but got: \\n\"\n",
    "                    f\"DP's global mesh: {dp_global_mesh}\\nTP's global mesh: {tp_global_mesh}\"\n",
    "                )\n",
    "            name_dims_error = \"FSDP requires named DeviceMesh dims for ND parallelism\"\n",
    "            assert dp_mesh.mesh_dim_names is not None, name_dims_error\n",
    "            assert tp_mesh.mesh_dim_names is not None, name_dims_error\n",
    "            submesh_names = dp_mesh.mesh_dim_names + tp_mesh.mesh_dim_names\n",
    "            self._spmd_mesh = dp_global_mesh[submesh_names]\n",
    "            if len(self._tp_spec.placements) != 1:\n",
    "                raise NotImplementedError(\n",
    "                    f\"FSDP only supports 1D TP, not {self._tp_spec.placements}\"\n",
    "                )\n",
    "            split_factor = self._tp_spec.num_shards_map[shard_dim]\n",
    "            assert (\n",
    "                2 <= self._spmd_mesh.ndim <= 3\n",
    "            ), f\"_spmd_mesh.ndim can only be 2 or 3 but got {self._spmd_mesh.ndim}.\"\n",
    "            self._spmd_placements: Tuple[Placement, ...]\n",
    "            dp_shard_tp_placement = (\n",
    "                (\n",
    "                    _StridedShard(shard_dim, split_factor=split_factor)\n",
    "                    if split_factor > 1\n",
    "                    else fsdp_placement\n",
    "                ),\n",
    "                self._tp_spec.placements[0],\n",
    "            )\n",
    "            if self._spmd_mesh.ndim == 2:\n",
    "                self._spmd_placements = dp_shard_tp_placement\n",
    "            else:\n",
    "                assert self.mesh_info.replicate_mesh_dim == 0\n",
    "                self._spmd_placements = (Replicate(),) + dp_shard_tp_placement\n",
    "            self._sharding_spec = DTensorSpec(\n",
    "                self._spmd_mesh,\n",
    "                self._spmd_placements,\n",
    "                tensor_meta=self._tp_spec.tensor_meta,\n",
    "            )\n",
    "            # TODO: Enable uneven sharding for FSDP+TP.\n",
    "            if split_factor > 1:  # FSDP has strided sharding on tensor dim 0\n",
    "                num_shards = self._sharding_spec.num_shards_map[0]\n",
    "                tensor_size_dim_0 = self._sharding_spec.shape[0]\n",
    "                if tensor_size_dim_0 % num_shards != 0:\n",
    "                    raise NotImplementedError(\n",
    "                        \"FSDP+TP sharding does not support uneven sharding for now: \"\n",
    "                        f\"tensor dim 0 has size {tensor_size_dim_0} which cannot be \"\n",
    "                        f\"evenly sharded into {num_shards} shards.\"\n",
    "                    )\n",
    "            param_data = cast(DTensor, param)._local_tensor\n",
    "        else:\n",
    "            self._spmd_mesh = self.mesh_info.mesh\n",
    "            if isinstance(self.mesh_info, HSDPMeshInfo):\n",
    "                self._spmd_placements = (Replicate(), fsdp_placement)\n",
    "            else:\n",
    "                self._spmd_placements = (fsdp_placement,)\n",
    "            self._sharding_spec = DTensorSpec(\n",
    "                self._spmd_mesh,\n",
    "                self._spmd_placements,\n",
    "                tensor_meta=TensorMeta(param.size(), param.stride(), param.dtype),\n",
    "            )\n",
    "            param_data = param\n",
    "        assert param_data.is_contiguous(), f\"{param_data.shape=} {param_data.stride()=}\"\n",
    "        shard_dim = fsdp_placement.dim\n",
    "        if shard_dim >= param_data.ndim:\n",
    "            raise AssertionError(\n",
    "                f\"Shard dim {shard_dim} is invalid for {param_data.ndim}D tensor: {param.shape}\"\n",
    "            )\n",
    "        self._orig_size = param_data.size()\n",
    "        self._contiguous_orig_stride = make_contiguous_strides_for(self._orig_size)\n",
    "        shard_rank = self.mesh_info.shard_mesh_rank\n",
    "        shard_world_size = self.mesh_info.shard_mesh_size\n",
    "        if shard_dim > 0 and param_data.size(shard_dim) % shard_world_size != 0:\n",
    "            # If sharding on nonzero dim, require even sharding for now because\n",
    "            # the uneven sharding (1) requires extra copies before/after FSDP\n",
    "            # collectives and (2) introduces extra complexity to handle padding\n",
    "            # and unpadding\n",
    "            raise NotImplementedError(\n",
    "                f\"FSDP does not support uneven sharding on dim {shard_dim}: \"\n",
    "                f\"{param_data.size()} (world size: {shard_world_size})\"\n",
    "            )\n",
    "        chunks = _chunk_with_empty(param_data, shard_world_size, dim=shard_dim)\n",
    "        sharded_param = chunks[shard_rank]\n",
    "        self.sharded_size = _get_dim_chunked_size(\n",
    "            sharded_param, param_data.size(), dim=shard_dim\n",
    "        )\n",
    "        self.contiguous_sharded_stride = make_contiguous_strides_for(self.sharded_size)\n",
    "        padded_sharded_size = chunks[0].size()  # 0th always padded\n",
    "        self.padded_sharded_param_size = padded_sharded_size\n",
    "        # Pre-pad the sharded parameter to avoid padding before all-gather\n",
    "        padded_sharded_param = param_data.new_zeros(padded_sharded_size)\n",
    "        if sharded_param.numel() > 0:\n",
    "            padded_sharded_param.narrow(\n",
    "                dim=shard_dim, start=0, length=sharded_param.size(shard_dim)\n",
    "            ).copy_(sharded_param)\n",
    "        if self.offload_to_cpu and not padded_sharded_param.is_meta:\n",
    "            padded_sharded_param = padded_sharded_param.cpu()\n",
    "            if self.pin_memory:\n",
    "                padded_sharded_param = padded_sharded_param.pin_memory(\n",
    "                    device=self.device\n",
    "                )\n",
    "        self._sharded_param_data = padded_sharded_param.view(-1)\n",
    "        length = sharded_param.size(shard_dim) if sharded_param.numel() > 0 else 0\n",
    "        sharded_param = padded_sharded_param.narrow(\n",
    "            dim=shard_dim, start=0, length=length\n",
    "        )\n",
    "        assert sharded_param.is_contiguous(), f\"{self.fsdp_placement=}\"\n",
    "        self.sharded_param = nn.Parameter(self.to_sharded_dtensor(sharded_param), requires_grad=param.requires_grad) # Literally a ONE line diff!\n",
    "        self.sharded_param.requires_grad_(param.requires_grad)\n",
    "        # Let `param_data` be freed normally when its ref count reaches 0 when\n",
    "        # the `fully_shard` call returns to allow provided parameters to alias\n",
    "        self._setattr_on_modules(self.sharded_param)\n",
    "        self.sharded_state = ShardedState.SHARDED\n",
    "\n",
    "    _init_sharded_param = FSDPParam._init_sharded_param\n",
    "    FSDPParam._init_sharded_param = _patched_init_sharded_param\n",
    "    \n",
    "import os\n",
    "def fsdp_main(world_size):\n",
    "    # For reproducability between training runs\n",
    "    import random\n",
    "    import numpy as np\n",
    "    os.environ[\"PYTHONHASHSEED\"] = \"3407\"\n",
    "    random.seed(3407)\n",
    "    np.random.seed(3407)\n",
    "    torch.manual_seed(3407)\n",
    "    torch.cuda.manual_seed(3407)\n",
    "    torch.cuda.manual_seed_all(3407)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    patch_fsdp()\n",
    "    mp_policy = os.environ.get(\"ACCELERATE_MIXED_PRECISION\", \"fp16\")\n",
    "    print(\"mp_policy:\", mp_policy)\n",
    "    rank = os.environ.get(\"LOCAL_RANK\", \"0\")\n",
    "    torch.cuda.set_device(int(rank))\n",
    "    max_seq_length = 2048\n",
    "    model_name = \"unsloth/meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "    param_type = torch.float32 # Everything in accelerate fsdp2 is upcast to float32\n",
    "    # if mp_policy == \"fp16\": param_type = torch.float16\n",
    "    if mp_policy == \"bf16\": param_type = torch.bfloat16\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit              = True,\n",
    "        bnb_4bit_use_double_quant = True,\n",
    "        bnb_4bit_quant_type       = \"nf4\",\n",
    "        bnb_4bit_compute_dtype    = param_type,\n",
    "        llm_int8_skip_modules = [\"lm_head\", \"multi_modal_projector\", \"merger\", \"modality_projection\"],\n",
    "    )\n",
    "    print(\"Visible devices\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "    device_map = {\"\": torch.cuda.current_device()}\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        attn_implementation = \"sdpa\",\n",
    "        quantization_config = bnb_config,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    lora_config = LoraConfig(\n",
    "        r = 64,\n",
    "        lora_alpha = 128,\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                          \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        lora_dropout = 0,\n",
    "        bias = \"none\",\n",
    "        task_type = TaskType.CAUSAL_LM,\n",
    "    )\n",
    "\n",
    "    # Get LoRA and setup model\n",
    "    model = get_peft_model(model, lora_config)\n",
    "\n",
    "    int_count = 0\n",
    "    nonint_count = 0\n",
    "    int_bytes = 0\n",
    "    nonint_bytes = 0\n",
    "    for n, p in model.named_parameters():\n",
    "        if p.dtype == torch.uint8:\n",
    "            int_bytes += p.numel() * p.element_size()\n",
    "            int_count += 1\n",
    "        else:\n",
    "            nonint_bytes += p.numel() * p.element_size()\n",
    "            nonint_count += 1\n",
    "    print(int_count, nonint_count)\n",
    "    print(int_bytes / (1024 ** 3), nonint_bytes / (1024 ** 3))\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if \".lora_A.\" in name or \".lora_B.\" in name: param.requires_grad_(True)\n",
    "            else: param.requires_grad_(False)\n",
    "\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.enable_input_require_grads()\n",
    "    # Get dataset\n",
    "    from datasets import load_dataset\n",
    "    from trl import SFTTrainer, SFTConfig\n",
    "    url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n",
    "    dataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train[:10%]\")\n",
    "    \n",
    "    assert torch.cuda.device_count() == 2\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    trainer = SFTTrainer(\n",
    "        model = model,\n",
    "        train_dataset = dataset,\n",
    "        processing_class = tokenizer,\n",
    "        args = SFTConfig(\n",
    "            per_device_train_batch_size = 2,\n",
    "            gradient_accumulation_steps = 4 // world_size, # 2 GPU x 2 steps = 1 GPU x 4 steps\n",
    "            warmup_steps = 1,\n",
    "            max_steps = 60,\n",
    "            logging_steps = 1,\n",
    "            output_dir = f\"outputs-{world_size}xGPU\",\n",
    "            overwrite_output_dir = True, \n",
    "            seed = 3407,\n",
    "            max_seq_length = max_seq_length,\n",
    "            fp16 = mp_policy == \"fp16\",  # These seem to override the `accelerate` config's MP policy.\n",
    "            bf16 = mp_policy == \"bf16\",  # Maybe worth looking into/raising an issue with the TRL/transformers team.\n",
    "            report_to = \"none\", # For W&B\n",
    "            dataset_num_proc = 4,\n",
    "            average_tokens_across_devices = world_size > 1,\n",
    "            gradient_checkpointing_kwargs={'use_reentrant':False},\n",
    "            ddp_find_unused_parameters = False,\n",
    "        ),\n",
    "    )\n",
    "    trainer.train()\n",
    "    print(\"Memory summary after\")\n",
    "    print(torch.cuda.memory_summary())\n",
    "    # Because colab, kaggle, and github notebook implementations are not uniform...\n",
    "    from ipywidgets import Widget\n",
    "    Widget.close_all()\n",
    "\n",
    "import os\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "fsdp_main(world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd87cfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:14:48.198426Z",
     "iopub.status.busy": "2025-04-10T05:14:48.198021Z",
     "iopub.status.idle": "2025-04-10T05:14:58.307134Z",
     "shell.execute_reply": "2025-04-10T05:14:58.306096Z"
    },
    "papermill": {
     "duration": 10.15883,
     "end_time": "2025-04-10T05:14:58.308635",
     "exception": false,
     "start_time": "2025-04-10T05:14:48.149805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Launch external script through accelerate with fsdp2 support passed via CLI flag.\n",
    "!accelerate to-fsdp2 --config_file /kaggle/working/fsdp_config.yaml --output_file /kaggle/working/fsdp2_config.yaml --overwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0138494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:14:58.410843Z",
     "iopub.status.busy": "2025-04-10T05:14:58.410559Z",
     "iopub.status.idle": "2025-04-10T05:25:15.542949Z",
     "shell.execute_reply": "2025-04-10T05:25:15.542157Z"
    },
    "papermill": {
     "duration": 617.185692,
     "end_time": "2025-04-10T05:25:15.544447",
     "exception": false,
     "start_time": "2025-04-10T05:14:58.358755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 05:15:11.118180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-10 05:15:11.118167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1744262111.324817     307 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1744262111.324800     306 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1744262111.382678     306 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1744262111.382679     307 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "mp_policy: fp16\r\n",
      "mp_policy: fp16\r\n",
      "Visible devices 0,1\r\n",
      "Visible devices 0,1\r\n",
      "config.json: 100%|█████████████████████████| 1.53k/1.53k [00:00<00:00, 10.1MB/s]\r\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:212: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\r\n",
      "  warnings.warn(warning_msg)\r\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:212: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\r\n",
      "  warnings.warn(warning_msg)\r\n",
      "model.safetensors: 100%|███████████████████▉| 5.70G/5.70G [00:13<00:00, 438MB/s]\r\n",
      "generation_config.json: 100%|██████████████████| 239/239 [00:00<00:00, 1.40MB/s]\r\n",
      "tokenizer_config.json: 100%|███████████████| 55.5k/55.5k [00:00<00:00, 8.86MB/s]\r\n",
      "tokenizer.json: 100%|██████████████████████| 17.2M/17.2M [00:00<00:00, 79.9MB/s]\r\n",
      "special_tokens_map.json: 100%|█████████████████| 454/454 [00:00<00:00, 2.76MB/s]\r\n",
      "224 515\r\n",
      "3.25 2.5825271606445312\r\n",
      "224 515\r\n",
      "3.25 2.5825271606445312\r\n",
      "unified_chip2.jsonl: 100%|█████████████████▉| 95.6M/95.6M [00:00<00:00, 255MB/s]\r\n",
      "Generating train split: 210289 examples [00:00, 298933.96 examples/s]\r\n",
      "[rank1]:[W410 05:15:53.865759502 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "Converting train dataset to ChatML (num_proc=4): 100%|█| 21029/21029 [00:00<00:0\r\n",
      "Applying chat template to train dataset (num_proc=4): 100%|█| 21029/21029 [00:02\r\n",
      "Tokenizing train dataset (num_proc=4): 100%|█| 21029/21029 [00:06<00:00, 3202.87\r\n",
      "Truncating train dataset (num_proc=4): 100%|█| 21029/21029 [00:00<00:00, 101056.\r\n",
      "[rank0]:[W410 05:16:05.105062790 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\r\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\r\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:576: UserWarning: FSDP upcast of low precision parameters to fp32 (since mixed_precision != 'no') may affect the precision of model checkpoints.\r\n",
      "  warnings.warn(\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\r\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\r\n",
      "{'loss': 2.1094, 'grad_norm': nan, 'learning_rate': 0.0, 'num_tokens': 802.0, 'mean_token_accuracy': 0.5929833650588989, 'epoch': 0.0}\r\n",
      "{'loss': 2.3354, 'grad_norm': nan, 'learning_rate': 0.0, 'num_tokens': 1527.0, 'mean_token_accuracy': 0.5363951921463013, 'epoch': 0.0}\r\n",
      "{'loss': 2.8762, 'grad_norm': 2.808506488800049, 'learning_rate': 0.0, 'num_tokens': 2099.0, 'mean_token_accuracy': 0.4402836114168167, 'epoch': 0.0}\r\n",
      "{'loss': 2.1719, 'grad_norm': 1.867788553237915, 'learning_rate': 2e-05, 'num_tokens': 2854.0, 'mean_token_accuracy': 0.5536948144435883, 'epoch': 0.0}\r\n",
      "{'loss': 2.0693, 'grad_norm': 1.448737621307373, 'learning_rate': 1.9661016949152545e-05, 'num_tokens': 3740.0, 'mean_token_accuracy': 0.5525306165218353, 'epoch': 0.0}\r\n",
      "{'loss': 2.0432, 'grad_norm': 1.389238715171814, 'learning_rate': 1.9322033898305087e-05, 'num_tokens': 4498.0, 'mean_token_accuracy': 0.563511461019516, 'epoch': 0.0}\r\n",
      "{'loss': 1.7227, 'grad_norm': 1.4242734909057617, 'learning_rate': 1.898305084745763e-05, 'num_tokens': 5241.0, 'mean_token_accuracy': 0.5606759786605835, 'epoch': 0.0}\r\n",
      "{'loss': 1.7747, 'grad_norm': 1.1274101734161377, 'learning_rate': 1.864406779661017e-05, 'num_tokens': 6194.0, 'mean_token_accuracy': 0.5835700929164886, 'epoch': 0.0}\r\n",
      "{'loss': 1.5991, 'grad_norm': 1.2553493976593018, 'learning_rate': 1.8305084745762713e-05, 'num_tokens': 6971.0, 'mean_token_accuracy': 0.6322021186351776, 'epoch': 0.0}\r\n",
      "{'loss': 1.8325, 'grad_norm': 1.421983003616333, 'learning_rate': 1.7966101694915256e-05, 'num_tokens': 7665.0, 'mean_token_accuracy': 0.5937117338180542, 'epoch': 0.0}\r\n",
      "{'loss': 1.6252, 'grad_norm': 1.4206427335739136, 'learning_rate': 1.76271186440678e-05, 'num_tokens': 8468.0, 'mean_token_accuracy': 0.6035238206386566, 'epoch': 0.0}\r\n",
      "{'loss': 1.741, 'grad_norm': 2.3235373497009277, 'learning_rate': 1.728813559322034e-05, 'num_tokens': 9254.0, 'mean_token_accuracy': 0.5765995979309082, 'epoch': 0.0}\r\n",
      "{'loss': 1.6655, 'grad_norm': 1.4998953342437744, 'learning_rate': 1.694915254237288e-05, 'num_tokens': 10103.0, 'mean_token_accuracy': 0.6033749878406525, 'epoch': 0.0}\r\n",
      "{'loss': 1.9585, 'grad_norm': 1.0015113353729248, 'learning_rate': 1.6610169491525424e-05, 'num_tokens': 11007.0, 'mean_token_accuracy': 0.5656080693006516, 'epoch': 0.01}\r\n",
      "{'loss': 1.9119, 'grad_norm': 1.5303893089294434, 'learning_rate': 1.6271186440677967e-05, 'num_tokens': 11700.0, 'mean_token_accuracy': 0.5547231435775757, 'epoch': 0.01}\r\n",
      "{'loss': 1.7556, 'grad_norm': 1.0759642124176025, 'learning_rate': 1.593220338983051e-05, 'num_tokens': 12402.0, 'mean_token_accuracy': 0.5793251991271973, 'epoch': 0.01}\r\n",
      "{'loss': 1.7454, 'grad_norm': 1.1386780738830566, 'learning_rate': 1.5593220338983053e-05, 'num_tokens': 13085.0, 'mean_token_accuracy': 0.5909110903739929, 'epoch': 0.01}\r\n",
      "{'loss': 1.5032, 'grad_norm': 1.0497329235076904, 'learning_rate': 1.5254237288135594e-05, 'num_tokens': 13924.0, 'mean_token_accuracy': 0.613755851984024, 'epoch': 0.01}\r\n",
      "{'loss': 1.203, 'grad_norm': 1.02323579788208, 'learning_rate': 1.4915254237288137e-05, 'num_tokens': 14650.0, 'mean_token_accuracy': 0.6499209403991699, 'epoch': 0.01}\r\n",
      "{'loss': 1.3374, 'grad_norm': 1.1078029870986938, 'learning_rate': 1.4576271186440678e-05, 'num_tokens': 15253.0, 'mean_token_accuracy': 0.6521609425544739, 'epoch': 0.01}\r\n",
      "{'loss': 1.9927, 'grad_norm': 1.2796530723571777, 'learning_rate': 1.4237288135593221e-05, 'num_tokens': 15835.0, 'mean_token_accuracy': 0.6198608577251434, 'epoch': 0.01}\r\n",
      "{'loss': 1.4475, 'grad_norm': 1.2633075714111328, 'learning_rate': 1.3898305084745764e-05, 'num_tokens': 16511.0, 'mean_token_accuracy': 0.6251268684864044, 'epoch': 0.01}\r\n",
      "{'loss': 1.8994, 'grad_norm': 1.3325080871582031, 'learning_rate': 1.3559322033898305e-05, 'num_tokens': 17118.0, 'mean_token_accuracy': 0.5445082783699036, 'epoch': 0.01}\r\n",
      "{'loss': 1.7964, 'grad_norm': 1.2084321975708008, 'learning_rate': 1.3220338983050848e-05, 'num_tokens': 17789.0, 'mean_token_accuracy': 0.589087575674057, 'epoch': 0.01}\r\n",
      "{'loss': 1.3632, 'grad_norm': 0.9119282960891724, 'learning_rate': 1.288135593220339e-05, 'num_tokens': 18633.0, 'mean_token_accuracy': 0.6183260977268219, 'epoch': 0.01}\r\n",
      "{'loss': 1.5903, 'grad_norm': 1.0437052249908447, 'learning_rate': 1.2542372881355932e-05, 'num_tokens': 19397.0, 'mean_token_accuracy': 0.6154080033302307, 'epoch': 0.01}\r\n",
      "{'loss': 1.9055, 'grad_norm': 1.4232057332992554, 'learning_rate': 1.2203389830508477e-05, 'num_tokens': 20238.0, 'mean_token_accuracy': 0.5799371600151062, 'epoch': 0.01}\r\n",
      "{'loss': 1.2296, 'grad_norm': 0.9278126358985901, 'learning_rate': 1.1864406779661018e-05, 'num_tokens': 21005.0, 'mean_token_accuracy': 0.6849409639835358, 'epoch': 0.01}\r\n",
      "{'loss': 1.899, 'grad_norm': 1.0924690961837769, 'learning_rate': 1.1525423728813561e-05, 'num_tokens': 21716.0, 'mean_token_accuracy': 0.5838392078876495, 'epoch': 0.01}\r\n",
      "{'loss': 1.7625, 'grad_norm': 1.2064069509506226, 'learning_rate': 1.1186440677966102e-05, 'num_tokens': 22454.0, 'mean_token_accuracy': 0.5763441622257233, 'epoch': 0.01}\r\n",
      "{'loss': 1.478, 'grad_norm': 1.021364688873291, 'learning_rate': 1.0847457627118645e-05, 'num_tokens': 23279.0, 'mean_token_accuracy': 0.6028772592544556, 'epoch': 0.01}\r\n",
      "{'loss': 1.9324, 'grad_norm': 1.0354431867599487, 'learning_rate': 1.0508474576271188e-05, 'num_tokens': 24082.0, 'mean_token_accuracy': 0.5724004507064819, 'epoch': 0.01}\r\n",
      "{'loss': 1.6414, 'grad_norm': 1.1284725666046143, 'learning_rate': 1.016949152542373e-05, 'num_tokens': 24756.0, 'mean_token_accuracy': 0.592511385679245, 'epoch': 0.01}\r\n",
      "{'loss': 1.3359, 'grad_norm': 0.989163875579834, 'learning_rate': 9.830508474576272e-06, 'num_tokens': 25535.0, 'mean_token_accuracy': 0.657776951789856, 'epoch': 0.01}\r\n",
      "{'loss': 2.0618, 'grad_norm': 1.2231160402297974, 'learning_rate': 9.491525423728815e-06, 'num_tokens': 26201.0, 'mean_token_accuracy': 0.557683140039444, 'epoch': 0.01}\r\n",
      "{'loss': 1.7561, 'grad_norm': 1.354550838470459, 'learning_rate': 9.152542372881356e-06, 'num_tokens': 26866.0, 'mean_token_accuracy': 0.5969054400920868, 'epoch': 0.01}\r\n",
      "{'loss': 1.4391, 'grad_norm': 1.2343604564666748, 'learning_rate': 8.8135593220339e-06, 'num_tokens': 27591.0, 'mean_token_accuracy': 0.6726614236831665, 'epoch': 0.01}\r\n",
      "{'loss': 1.9044, 'grad_norm': 1.2257273197174072, 'learning_rate': 8.47457627118644e-06, 'num_tokens': 28273.0, 'mean_token_accuracy': 0.5541283935308456, 'epoch': 0.01}\r\n",
      "{'loss': 1.7047, 'grad_norm': 1.5894659757614136, 'learning_rate': 8.135593220338983e-06, 'num_tokens': 28918.0, 'mean_token_accuracy': 0.6122584640979767, 'epoch': 0.01}\r\n",
      "{'loss': 1.4487, 'grad_norm': 1.3467402458190918, 'learning_rate': 7.796610169491526e-06, 'num_tokens': 29547.0, 'mean_token_accuracy': 0.6187040209770203, 'epoch': 0.02}\r\n",
      "{'loss': 1.2046, 'grad_norm': 1.340754747390747, 'learning_rate': 7.4576271186440685e-06, 'num_tokens': 30103.0, 'mean_token_accuracy': 0.6725366711616516, 'epoch': 0.02}\r\n",
      "{'loss': 1.7599, 'grad_norm': 1.198117733001709, 'learning_rate': 7.1186440677966106e-06, 'num_tokens': 30764.0, 'mean_token_accuracy': 0.6225669682025909, 'epoch': 0.02}\r\n",
      "{'loss': 1.4161, 'grad_norm': 1.2479745149612427, 'learning_rate': 6.779661016949153e-06, 'num_tokens': 31463.0, 'mean_token_accuracy': 0.6222330927848816, 'epoch': 0.02}\r\n",
      "{'loss': 1.855, 'grad_norm': 1.310686469078064, 'learning_rate': 6.440677966101695e-06, 'num_tokens': 32040.0, 'mean_token_accuracy': 0.5766990482807159, 'epoch': 0.02}\r\n",
      "{'loss': 1.5691, 'grad_norm': 1.0087779760360718, 'learning_rate': 6.1016949152542385e-06, 'num_tokens': 32875.0, 'mean_token_accuracy': 0.5820018649101257, 'epoch': 0.02}\r\n",
      "{'loss': 1.7344, 'grad_norm': 1.1063181161880493, 'learning_rate': 5.7627118644067805e-06, 'num_tokens': 33642.0, 'mean_token_accuracy': 0.5798381865024567, 'epoch': 0.02}\r\n",
      "{'loss': 1.3934, 'grad_norm': 1.0130335092544556, 'learning_rate': 5.423728813559323e-06, 'num_tokens': 34480.0, 'mean_token_accuracy': 0.6079317331314087, 'epoch': 0.02}\r\n",
      "{'loss': 1.6443, 'grad_norm': 1.0788497924804688, 'learning_rate': 5.084745762711865e-06, 'num_tokens': 35331.0, 'mean_token_accuracy': 0.5893864631652832, 'epoch': 0.02}\r\n",
      "{'loss': 1.5522, 'grad_norm': 1.1548537015914917, 'learning_rate': 4.745762711864408e-06, 'num_tokens': 36049.0, 'mean_token_accuracy': 0.6000834405422211, 'epoch': 0.02}\r\n",
      "{'loss': 1.5195, 'grad_norm': 1.2844393253326416, 'learning_rate': 4.40677966101695e-06, 'num_tokens': 36848.0, 'mean_token_accuracy': 0.6083642244338989, 'epoch': 0.02}\r\n",
      "{'loss': 1.7228, 'grad_norm': 1.1724478006362915, 'learning_rate': 4.067796610169492e-06, 'num_tokens': 37667.0, 'mean_token_accuracy': 0.6139193177223206, 'epoch': 0.02}\r\n",
      "{'loss': 1.6191, 'grad_norm': 1.4806684255599976, 'learning_rate': 3.7288135593220342e-06, 'num_tokens': 38278.0, 'mean_token_accuracy': 0.6254078447818756, 'epoch': 0.02}\r\n",
      "{'loss': 1.7356, 'grad_norm': 1.2287019491195679, 'learning_rate': 3.3898305084745763e-06, 'num_tokens': 38940.0, 'mean_token_accuracy': 0.6131057739257812, 'epoch': 0.02}\r\n",
      "{'loss': 1.6171, 'grad_norm': 1.0647906064987183, 'learning_rate': 3.0508474576271192e-06, 'num_tokens': 39744.0, 'mean_token_accuracy': 0.5928775072097778, 'epoch': 0.02}\r\n",
      "{'loss': 1.3284, 'grad_norm': 1.39249587059021, 'learning_rate': 2.7118644067796613e-06, 'num_tokens': 40332.0, 'mean_token_accuracy': 0.6544992625713348, 'epoch': 0.02}\r\n",
      "{'loss': 1.394, 'grad_norm': 1.1121481657028198, 'learning_rate': 2.372881355932204e-06, 'num_tokens': 41142.0, 'mean_token_accuracy': 0.6223120987415314, 'epoch': 0.02}\r\n",
      "{'loss': 1.4846, 'grad_norm': 1.5246496200561523, 'learning_rate': 2.033898305084746e-06, 'num_tokens': 41705.0, 'mean_token_accuracy': 0.6044884026050568, 'epoch': 0.02}\r\n",
      "{'loss': 1.6248, 'grad_norm': 1.3247263431549072, 'learning_rate': 1.6949152542372882e-06, 'num_tokens': 42327.0, 'mean_token_accuracy': 0.6503290235996246, 'epoch': 0.02}\r\n",
      "{'loss': 1.4907, 'grad_norm': 1.081577181816101, 'learning_rate': 1.3559322033898307e-06, 'num_tokens': 43297.0, 'mean_token_accuracy': 0.6181572675704956, 'epoch': 0.02}\r\n",
      "{'loss': 1.3159, 'grad_norm': 1.8411110639572144, 'learning_rate': 1.016949152542373e-06, 'num_tokens': 43735.0, 'mean_token_accuracy': 0.665260374546051, 'epoch': 0.02}\r\n",
      "100%|███████████████████████████████████████████| 60/60 [08:49<00:00,  8.76s/it]/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:120: FutureWarning: `save_state_dict` is deprecated and will be removed in future versions.Please use `save` instead.\r\n",
      "  dist_cp.save_state_dict(\r\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:120: FutureWarning: `save_state_dict` is deprecated and will be removed in future versions.Please use `save` instead.\r\n",
      "  dist_cp.save_state_dict(\r\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:236: FutureWarning: `save_state_dict` is deprecated and will be removed in future versions.Please use `save` instead.\r\n",
      "  dist_cp.save_state_dict(\r\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/utils/fsdp_utils.py:236: FutureWarning: `save_state_dict` is deprecated and will be removed in future versions.Please use `save` instead.\r\n",
      "  dist_cp.save_state_dict(\r\n",
      "{'train_runtime': 541.5093, 'train_samples_per_second': 0.886, 'train_steps_per_second': 0.111, 'train_loss': 1.6925211588541667, 'epoch': 0.02}\r\n",
      "100%|███████████████████████████████████████████| 60/60 [09:01<00:00,  8.76s/it]Memory summary after\r\n",
      "100%|███████████████████████████████████████████| 60/60 [09:01<00:00,  9.02s/it]\r\n",
      "|===========================================================================|\r\n",
      "|                  PyTorch CUDA memory summary, device ID 1                 |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 1         |\r\n",
      "|===========================================================================|\r\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocated memory      |   5770 MiB |  13723 MiB |  20462 GiB |  20456 GiB |\r\n",
      "|       from large pool |   5144 MiB |  12576 MiB |  20187 GiB |  20182 GiB |\r\n",
      "|       from small pool |    626 MiB |   1148 MiB |    274 GiB |    273 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active memory         |   5770 MiB |  13723 MiB |  20462 GiB |  20456 GiB |\r\n",
      "|       from large pool |   5144 MiB |  12576 MiB |  20187 GiB |  20182 GiB |\r\n",
      "|       from small pool |    626 MiB |   1148 MiB |    274 GiB |    273 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Requested memory      |   5752 MiB |  13693 MiB |  20453 GiB |  20448 GiB |\r\n",
      "|       from large pool |   5126 MiB |  12546 MiB |  20179 GiB |  20174 GiB |\r\n",
      "|       from small pool |    626 MiB |   1148 MiB |    274 GiB |    273 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved memory   |   9642 MiB |  14330 MiB |  19786 MiB |  10144 MiB |\r\n",
      "|       from large pool |   8860 MiB |  13180 MiB |  18180 MiB |   9320 MiB |\r\n",
      "|       from small pool |    782 MiB |   1150 MiB |   1606 MiB |    824 MiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocations           |    2762    |    4012    |    2547 K  |    2544 K  |\r\n",
      "|       from large pool |     453    |     935    |    1475 K  |    1475 K  |\r\n",
      "|       from small pool |    2309    |    3078    |    1071 K  |    1069 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active allocs         |    2763    |    4012    |    2547 K  |    2544 K  |\r\n",
      "|       from large pool |     453    |     935    |    1475 K  |    1475 K  |\r\n",
      "|       from small pool |    2310    |    3078    |    1071 K  |    1069 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\r\n",
      "|===========================================================================|\r\n",
      "Memory summary after\r\n",
      "\r\n",
      "|===========================================================================|\r\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\r\n",
      "|===========================================================================|\r\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocated memory      |   5770 MiB |  12715 MiB |  20264 GiB |  20258 GiB |\r\n",
      "|       from large pool |   5144 MiB |  11568 MiB |  20004 GiB |  19999 GiB |\r\n",
      "|       from small pool |    626 MiB |   1147 MiB |    259 GiB |    259 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active memory         |   5770 MiB |  12715 MiB |  20264 GiB |  20258 GiB |\r\n",
      "|       from large pool |   5144 MiB |  11568 MiB |  20004 GiB |  19999 GiB |\r\n",
      "|       from small pool |    626 MiB |   1147 MiB |    259 GiB |    259 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Requested memory      |   5752 MiB |  12691 MiB |  20256 GiB |  20250 GiB |\r\n",
      "|       from large pool |   5126 MiB |  11544 MiB |  19996 GiB |  19991 GiB |\r\n",
      "|       from small pool |    626 MiB |   1147 MiB |    259 GiB |    259 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved memory   |  14590 MiB |  14590 MiB |  16090 MiB |   1500 MiB |\r\n",
      "|       from large pool |  13440 MiB |  13440 MiB |  14940 MiB |   1500 MiB |\r\n",
      "|       from small pool |   1150 MiB |   1150 MiB |   1150 MiB |      0 MiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocations           |    2762    |    4011    |    2546 K  |    2544 K  |\r\n",
      "|       from large pool |     453    |     934    |    1485 K  |    1484 K  |\r\n",
      "|       from small pool |    2309    |    3077    |    1061 K  |    1059 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active allocs         |    2767    |    4011    |    2546 K  |    2544 K  |\r\n",
      "|       from large pool |     453    |     934    |    1485 K  |    1484 K  |\r\n",
      "|       from small pool |    2314    |    3077    |    1061 K  |    1059 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\r\n",
      "|===========================================================================|\r\n",
      "\r\n",
      "[rank0]:[W410 05:25:11.242934391 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file /kaggle/working/fsdp2_config.yaml /kaggle/working/train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2ae79",
   "metadata": {
    "papermill": {
     "duration": 0.058826,
     "end_time": "2025-04-10T05:25:15.663852",
     "exception": false,
     "start_time": "2025-04-10T05:25:15.605026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: Peak memory usage is rather high due to a known bug with weight loading in `accelerate`, https://github.com/huggingface/accelerate/pull/3482\n",
    "\n",
    "We can see from the stats below that the actual distributed training saves memory during training. At the moment, these savings are sadly ineffective due to our high peak. I have some working ideas on how to fix this, however at the time of writing this it seems it may not be so easy, as it would require moving the quantized params to and from a meta tensor, which would involve messing around with `Params4bit.__torch_dispatch__` in ways I am not very familiar with.\n",
    "\n",
    "This notebook was meant to be an initial first look at this problem, so I am presenting an MVP without a fix for the above issue. Unless I'm missing something obvious, getting this feature productionized to spec (i.e. must use bnb qlora, fsdp2 with all features, hf trainer) requires sending out multiple patches to every single one of these repos. In addition, there are probably many aspects I've missed, and the performance of this toy prototype leaves much room for improvement (My use of fully_shard is nowhere near optimal, for example).\n",
    "\n",
    "In my opinion this feature is actually pretty large and has a lot of small subgoals that need to all be met. Maybe next month if I have time and their support I could work with them on getting a production grade version of this feature out :P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6256c",
   "metadata": {
    "papermill": {
     "duration": 0.058061,
     "end_time": "2025-04-10T05:25:15.782267",
     "exception": false,
     "start_time": "2025-04-10T05:25:15.724206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's compare with a single threaded training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801b7cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:25:15.902141Z",
     "iopub.status.busy": "2025-04-10T05:25:15.901569Z",
     "iopub.status.idle": "2025-04-10T05:34:13.857089Z",
     "shell.execute_reply": "2025-04-10T05:34:13.856077Z"
    },
    "papermill": {
     "duration": 538.017986,
     "end_time": "2025-04-10T05:34:13.858868",
     "exception": false,
     "start_time": "2025-04-10T05:25:15.840882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 05:25:21.504258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1744262721.528224     653 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1744262721.535698     653 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "mp_policy: fp16\r\n",
      "Visible devices 0,1\r\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:212: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\r\n",
      "  warnings.warn(warning_msg)\r\n",
      "224 515\r\n",
      "3.25 2.5825271606445312\r\n",
      "[rank0]:[W410 05:25:34.176312097 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\r\n",
      "{'loss': 2.109, 'grad_norm': 2.761431932449341, 'learning_rate': 0.0, 'num_tokens': 802.0, 'mean_token_accuracy': 0.5716155543923378, 'epoch': 0.0}\r\n",
      "{'loss': 2.3357, 'grad_norm': 2.7907538414001465, 'learning_rate': 2e-05, 'num_tokens': 1527.0, 'mean_token_accuracy': 0.5286831930279732, 'epoch': 0.0}\r\n",
      "{'loss': 2.7482, 'grad_norm': 2.9637274742126465, 'learning_rate': 1.9661016949152545e-05, 'num_tokens': 2099.0, 'mean_token_accuracy': 0.4340626746416092, 'epoch': 0.0}\r\n",
      "{'loss': 2.0025, 'grad_norm': 2.066816806793213, 'learning_rate': 1.9322033898305087e-05, 'num_tokens': 2854.0, 'mean_token_accuracy': 0.5638100504875183, 'epoch': 0.0}\r\n",
      "{'loss': 1.9315, 'grad_norm': 2.1084344387054443, 'learning_rate': 1.898305084745763e-05, 'num_tokens': 3740.0, 'mean_token_accuracy': 0.5638914257287979, 'epoch': 0.0}\r\n",
      "{'loss': 1.9146, 'grad_norm': 1.6865925788879395, 'learning_rate': 1.864406779661017e-05, 'num_tokens': 4498.0, 'mean_token_accuracy': 0.5844787806272507, 'epoch': 0.0}\r\n",
      "{'loss': 1.6166, 'grad_norm': 1.9251699447631836, 'learning_rate': 1.8305084745762713e-05, 'num_tokens': 5241.0, 'mean_token_accuracy': 0.5837393999099731, 'epoch': 0.0}\r\n",
      "{'loss': 1.7029, 'grad_norm': 1.7242870330810547, 'learning_rate': 1.7966101694915256e-05, 'num_tokens': 6194.0, 'mean_token_accuracy': 0.5883872658014297, 'epoch': 0.0}\r\n",
      "{'loss': 1.5294, 'grad_norm': 1.8190590143203735, 'learning_rate': 1.76271186440678e-05, 'num_tokens': 6971.0, 'mean_token_accuracy': 0.6447521150112152, 'epoch': 0.0}\r\n",
      "{'loss': 1.7809, 'grad_norm': 3.069944143295288, 'learning_rate': 1.728813559322034e-05, 'num_tokens': 7665.0, 'mean_token_accuracy': 0.5981811806559563, 'epoch': 0.0}\r\n",
      "{'loss': 1.5864, 'grad_norm': 2.051600694656372, 'learning_rate': 1.694915254237288e-05, 'num_tokens': 8468.0, 'mean_token_accuracy': 0.6127491146326065, 'epoch': 0.0}\r\n",
      "{'loss': 1.7096, 'grad_norm': 1.561495065689087, 'learning_rate': 1.6610169491525424e-05, 'num_tokens': 9254.0, 'mean_token_accuracy': 0.5713861733675003, 'epoch': 0.0}\r\n",
      "{'loss': 1.632, 'grad_norm': 1.3815494775772095, 'learning_rate': 1.6271186440677967e-05, 'num_tokens': 10103.0, 'mean_token_accuracy': 0.6014201641082764, 'epoch': 0.0}\r\n",
      "{'loss': 1.9387, 'grad_norm': 1.4655423164367676, 'learning_rate': 1.593220338983051e-05, 'num_tokens': 11007.0, 'mean_token_accuracy': 0.5737158507108688, 'epoch': 0.01}\r\n",
      "{'loss': 1.8686, 'grad_norm': 2.260178565979004, 'learning_rate': 1.5593220338983053e-05, 'num_tokens': 11700.0, 'mean_token_accuracy': 0.546062096953392, 'epoch': 0.01}\r\n",
      "{'loss': 1.7344, 'grad_norm': 1.5504860877990723, 'learning_rate': 1.5254237288135594e-05, 'num_tokens': 12402.0, 'mean_token_accuracy': 0.5854815989732742, 'epoch': 0.01}\r\n",
      "{'loss': 1.72, 'grad_norm': 1.8783193826675415, 'learning_rate': 1.4915254237288137e-05, 'num_tokens': 13085.0, 'mean_token_accuracy': 0.5804883688688278, 'epoch': 0.01}\r\n",
      "{'loss': 1.4834, 'grad_norm': 1.4602727890014648, 'learning_rate': 1.4576271186440678e-05, 'num_tokens': 13924.0, 'mean_token_accuracy': 0.6251178234815598, 'epoch': 0.01}\r\n",
      "{'loss': 1.1883, 'grad_norm': 1.4555377960205078, 'learning_rate': 1.4237288135593221e-05, 'num_tokens': 14650.0, 'mean_token_accuracy': 0.650083139538765, 'epoch': 0.01}\r\n",
      "{'loss': 1.3276, 'grad_norm': 1.736279845237732, 'learning_rate': 1.3898305084745764e-05, 'num_tokens': 15253.0, 'mean_token_accuracy': 0.656538650393486, 'epoch': 0.01}\r\n",
      "{'loss': 1.9777, 'grad_norm': 1.8394898176193237, 'learning_rate': 1.3559322033898305e-05, 'num_tokens': 15835.0, 'mean_token_accuracy': 0.6208020225167274, 'epoch': 0.01}\r\n",
      "{'loss': 1.4312, 'grad_norm': 1.6885266304016113, 'learning_rate': 1.3220338983050848e-05, 'num_tokens': 16511.0, 'mean_token_accuracy': 0.6252682209014893, 'epoch': 0.01}\r\n",
      "{'loss': 1.8707, 'grad_norm': 1.747586727142334, 'learning_rate': 1.288135593220339e-05, 'num_tokens': 17118.0, 'mean_token_accuracy': 0.5484975874423981, 'epoch': 0.01}\r\n",
      "{'loss': 1.7793, 'grad_norm': 1.573699951171875, 'learning_rate': 1.2542372881355932e-05, 'num_tokens': 17789.0, 'mean_token_accuracy': 0.586950808763504, 'epoch': 0.01}\r\n",
      "{'loss': 1.3478, 'grad_norm': 1.3253207206726074, 'learning_rate': 1.2203389830508477e-05, 'num_tokens': 18633.0, 'mean_token_accuracy': 0.6216249167919159, 'epoch': 0.01}\r\n",
      "{'loss': 1.5788, 'grad_norm': 1.525765061378479, 'learning_rate': 1.1864406779661018e-05, 'num_tokens': 19397.0, 'mean_token_accuracy': 0.6066128462553024, 'epoch': 0.01}\r\n",
      "{'loss': 1.8793, 'grad_norm': 1.9173356294631958, 'learning_rate': 1.1525423728813561e-05, 'num_tokens': 20238.0, 'mean_token_accuracy': 0.5844110623002052, 'epoch': 0.01}\r\n",
      "{'loss': 1.2167, 'grad_norm': 1.363087773323059, 'learning_rate': 1.1186440677966102e-05, 'num_tokens': 21005.0, 'mean_token_accuracy': 0.6866213977336884, 'epoch': 0.01}\r\n",
      "{'loss': 1.8859, 'grad_norm': 1.5278265476226807, 'learning_rate': 1.0847457627118645e-05, 'num_tokens': 21716.0, 'mean_token_accuracy': 0.5888724625110626, 'epoch': 0.01}\r\n",
      "{'loss': 1.7598, 'grad_norm': 1.6995840072631836, 'learning_rate': 1.0508474576271188e-05, 'num_tokens': 22454.0, 'mean_token_accuracy': 0.5736943259835243, 'epoch': 0.01}\r\n",
      "{'loss': 1.4583, 'grad_norm': 1.4594014883041382, 'learning_rate': 1.016949152542373e-05, 'num_tokens': 23279.0, 'mean_token_accuracy': 0.6032126843929291, 'epoch': 0.01}\r\n",
      "{'loss': 1.9182, 'grad_norm': 1.4833314418792725, 'learning_rate': 9.830508474576272e-06, 'num_tokens': 24082.0, 'mean_token_accuracy': 0.5764820873737335, 'epoch': 0.01}\r\n",
      "{'loss': 1.6262, 'grad_norm': 1.6799670457839966, 'learning_rate': 9.491525423728815e-06, 'num_tokens': 24756.0, 'mean_token_accuracy': 0.6000279188156128, 'epoch': 0.01}\r\n",
      "{'loss': 1.3281, 'grad_norm': 1.419983983039856, 'learning_rate': 9.152542372881356e-06, 'num_tokens': 25535.0, 'mean_token_accuracy': 0.6622576117515564, 'epoch': 0.01}\r\n",
      "{'loss': 2.0512, 'grad_norm': 1.7838797569274902, 'learning_rate': 8.8135593220339e-06, 'num_tokens': 26201.0, 'mean_token_accuracy': 0.5598855316638947, 'epoch': 0.01}\r\n",
      "{'loss': 1.7418, 'grad_norm': 1.8906755447387695, 'learning_rate': 8.47457627118644e-06, 'num_tokens': 26866.0, 'mean_token_accuracy': 0.6024011373519897, 'epoch': 0.01}\r\n",
      "{'loss': 1.4286, 'grad_norm': 1.9138822555541992, 'learning_rate': 8.135593220338983e-06, 'num_tokens': 27591.0, 'mean_token_accuracy': 0.679544135928154, 'epoch': 0.01}\r\n",
      "{'loss': 1.8857, 'grad_norm': 1.8888137340545654, 'learning_rate': 7.796610169491526e-06, 'num_tokens': 28273.0, 'mean_token_accuracy': 0.558152325451374, 'epoch': 0.01}\r\n",
      "{'loss': 1.6881, 'grad_norm': 2.292546033859253, 'learning_rate': 7.4576271186440685e-06, 'num_tokens': 28918.0, 'mean_token_accuracy': 0.6073435246944427, 'epoch': 0.01}\r\n",
      "{'loss': 1.4423, 'grad_norm': 1.8781545162200928, 'learning_rate': 7.1186440677966106e-06, 'num_tokens': 29547.0, 'mean_token_accuracy': 0.6278396546840668, 'epoch': 0.02}\r\n",
      "{'loss': 1.1926, 'grad_norm': 1.9288139343261719, 'learning_rate': 6.779661016949153e-06, 'num_tokens': 30103.0, 'mean_token_accuracy': 0.6649714112281799, 'epoch': 0.02}\r\n",
      "{'loss': 1.7524, 'grad_norm': 1.725667119026184, 'learning_rate': 6.440677966101695e-06, 'num_tokens': 30764.0, 'mean_token_accuracy': 0.6234308332204819, 'epoch': 0.02}\r\n",
      "{'loss': 1.3974, 'grad_norm': 1.8224363327026367, 'learning_rate': 6.1016949152542385e-06, 'num_tokens': 31463.0, 'mean_token_accuracy': 0.6252522766590118, 'epoch': 0.02}\r\n",
      "{'loss': 1.8576, 'grad_norm': 1.9591623544692993, 'learning_rate': 5.7627118644067805e-06, 'num_tokens': 32040.0, 'mean_token_accuracy': 0.5727895349264145, 'epoch': 0.02}\r\n",
      "{'loss': 1.5651, 'grad_norm': 1.4709477424621582, 'learning_rate': 5.423728813559323e-06, 'num_tokens': 32875.0, 'mean_token_accuracy': 0.5776873528957367, 'epoch': 0.02}\r\n",
      "{'loss': 1.7285, 'grad_norm': 1.5659524202346802, 'learning_rate': 5.084745762711865e-06, 'num_tokens': 33642.0, 'mean_token_accuracy': 0.5898279845714569, 'epoch': 0.02}\r\n",
      "{'loss': 1.3851, 'grad_norm': 1.460158348083496, 'learning_rate': 4.745762711864408e-06, 'num_tokens': 34480.0, 'mean_token_accuracy': 0.613837331533432, 'epoch': 0.02}\r\n",
      "{'loss': 1.6398, 'grad_norm': 1.5966726541519165, 'learning_rate': 4.40677966101695e-06, 'num_tokens': 35331.0, 'mean_token_accuracy': 0.6048985421657562, 'epoch': 0.02}\r\n",
      "{'loss': 1.5456, 'grad_norm': 1.703074336051941, 'learning_rate': 4.067796610169492e-06, 'num_tokens': 36049.0, 'mean_token_accuracy': 0.5915876924991608, 'epoch': 0.02}\r\n",
      "{'loss': 1.5205, 'grad_norm': 1.8226501941680908, 'learning_rate': 3.7288135593220342e-06, 'num_tokens': 36848.0, 'mean_token_accuracy': 0.6117792427539825, 'epoch': 0.02}\r\n",
      "{'loss': 1.7124, 'grad_norm': 1.7543991804122925, 'learning_rate': 3.3898305084745763e-06, 'num_tokens': 37667.0, 'mean_token_accuracy': 0.6169469207525253, 'epoch': 0.02}\r\n",
      "{'loss': 1.6122, 'grad_norm': 2.1417109966278076, 'learning_rate': 3.0508474576271192e-06, 'num_tokens': 38278.0, 'mean_token_accuracy': 0.6346897929906845, 'epoch': 0.02}\r\n",
      "{'loss': 1.7279, 'grad_norm': 1.7717047929763794, 'learning_rate': 2.7118644067796613e-06, 'num_tokens': 38940.0, 'mean_token_accuracy': 0.6124410629272461, 'epoch': 0.02}\r\n",
      "{'loss': 1.6112, 'grad_norm': 1.5467329025268555, 'learning_rate': 2.372881355932204e-06, 'num_tokens': 39744.0, 'mean_token_accuracy': 0.6097398400306702, 'epoch': 0.02}\r\n",
      "{'loss': 1.3278, 'grad_norm': 1.9858675003051758, 'learning_rate': 2.033898305084746e-06, 'num_tokens': 40332.0, 'mean_token_accuracy': 0.6561645269393921, 'epoch': 0.02}\r\n",
      "{'loss': 1.3929, 'grad_norm': 1.5659650564193726, 'learning_rate': 1.6949152542372882e-06, 'num_tokens': 41142.0, 'mean_token_accuracy': 0.6268204003572464, 'epoch': 0.02}\r\n",
      "{'loss': 1.4889, 'grad_norm': 2.3319597244262695, 'learning_rate': 1.3559322033898307e-06, 'num_tokens': 41705.0, 'mean_token_accuracy': 0.5995683968067169, 'epoch': 0.02}\r\n",
      "{'loss': 1.6229, 'grad_norm': 1.9294894933700562, 'learning_rate': 1.016949152542373e-06, 'num_tokens': 42327.0, 'mean_token_accuracy': 0.6544188112020493, 'epoch': 0.02}\r\n",
      "{'loss': 1.4859, 'grad_norm': 1.5880333185195923, 'learning_rate': 6.779661016949153e-07, 'num_tokens': 43297.0, 'mean_token_accuracy': 0.6201644241809845, 'epoch': 0.02}\r\n",
      "{'loss': 1.319, 'grad_norm': 2.7283005714416504, 'learning_rate': 3.3898305084745766e-07, 'num_tokens': 43735.0, 'mean_token_accuracy': 0.6665477305650711, 'epoch': 0.02}\r\n",
      "{'train_runtime': 515.5829, 'train_samples_per_second': 0.931, 'train_steps_per_second': 0.116, 'train_loss': 1.6673652867476145, 'epoch': 0.02}\r\n",
      "100%|███████████████████████████████████████████| 60/60 [08:35<00:00,  8.59s/it]\r\n",
      "Memory summary after\r\n",
      "|===========================================================================|\r\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\r\n",
      "|===========================================================================|\r\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocated memory      |   8026 MiB |   9842 MiB |  23953 GiB |  23945 GiB |\r\n",
      "|       from large pool |   7007 MiB |   8366 MiB |  23475 GiB |  23468 GiB |\r\n",
      "|       from small pool |   1019 MiB |   1627 MiB |    478 GiB |    477 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active memory         |   8026 MiB |  10559 MiB |  23953 GiB |  23945 GiB |\r\n",
      "|       from large pool |   7007 MiB |  10149 MiB |  23475 GiB |  23468 GiB |\r\n",
      "|       from small pool |   1019 MiB |   1627 MiB |    478 GiB |    477 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Requested memory      |   8014 MiB |  10541 MiB |  23951 GiB |  23943 GiB |\r\n",
      "|       from large pool |   6995 MiB |  10131 MiB |  23473 GiB |  23466 GiB |\r\n",
      "|       from small pool |   1019 MiB |   1627 MiB |    478 GiB |    477 GiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved memory   |  11838 MiB |  11838 MiB |  13338 MiB |   1500 MiB |\r\n",
      "|       from large pool |  10200 MiB |  10200 MiB |  11700 MiB |   1500 MiB |\r\n",
      "|       from small pool |   1638 MiB |   1638 MiB |   1638 MiB |      0 MiB |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Allocations           |    2787    |    3746    |    3198 K  |    3195 K  |\r\n",
      "|       from large pool |     541    |     772    |    1899 K  |    1898 K  |\r\n",
      "|       from small pool |    2246    |    3065    |    1298 K  |    1296 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Active allocs         |    2788    |    3746    |    3198 K  |    3195 K  |\r\n",
      "|       from large pool |     541    |     772    |    1899 K  |    1898 K  |\r\n",
      "|       from small pool |    2247    |    3065    |    1298 K  |    1296 K  |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\r\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\r\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\r\n",
      "|---------------------------------------------------------------------------|\r\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\r\n",
      "|===========================================================================|\r\n",
      "\r\n",
      "[rank0]:[W410 05:34:11.795014188 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!LOCAL_RANK=0 RANK=0 WORLD_SIZE=1 MASTER_ADDR=0 MASTER_PORT=0 python /kaggle/working/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4040c8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:34:13.997056Z",
     "iopub.status.busy": "2025-04-10T05:34:13.996759Z",
     "iopub.status.idle": "2025-04-10T05:34:14.330640Z",
     "shell.execute_reply": "2025-04-10T05:34:14.329835Z"
    },
    "papermill": {
     "duration": 0.403612,
     "end_time": "2025-04-10T05:34:14.331970",
     "exception": false,
     "start_time": "2025-04-10T05:34:13.928358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Show and export loss curve for 2x GPU\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "train_loss = []\n",
    "with open(\"/kaggle/working/outputs-2xGPU/checkpoint-60/trainer_state.json\", \"r\") as f:\n",
    "    trainer_state = json.load(f)\n",
    "for elem in trainer_state[\"log_history\"]:\n",
    "    if 'loss' in elem.keys():\n",
    "        train_loss.append(elem['loss'])\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(f\"Loss curve when using 2 GPUs\")\n",
    "plt.savefig(f\"llama_8b_2x_GPU_loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db43f14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:34:14.467707Z",
     "iopub.status.busy": "2025-04-10T05:34:14.467500Z",
     "iopub.status.idle": "2025-04-10T05:34:14.718281Z",
     "shell.execute_reply": "2025-04-10T05:34:14.717536Z"
    },
    "papermill": {
     "duration": 0.319417,
     "end_time": "2025-04-10T05:34:14.719538",
     "exception": false,
     "start_time": "2025-04-10T05:34:14.400121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Show and export loss curve for 1x GPU\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "train_loss = []\n",
    "with open(\"/kaggle/working/outputs-1xGPU/checkpoint-60/trainer_state.json\", \"r\") as f:\n",
    "    trainer_state = json.load(f)\n",
    "for elem in trainer_state[\"log_history\"]:\n",
    "    if 'loss' in elem.keys():\n",
    "        train_loss.append(elem['loss'])\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(f\"Loss curve when using 1 GPU\")\n",
    "plt.savefig(f\"llama_8b_1x_GPU_loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d57d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T05:34:14.859968Z",
     "iopub.status.busy": "2025-04-10T05:34:14.859394Z",
     "iopub.status.idle": "2025-04-10T05:34:14.923441Z",
     "shell.execute_reply": "2025-04-10T05:34:14.922939Z"
    },
    "papermill": {
     "duration": 0.133793,
     "end_time": "2025-04-10T05:34:14.924437",
     "exception": false,
     "start_time": "2025-04-10T05:34:14.790644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Because colab, kaggle, and github notebook implementations are not uniform...\n",
    "from ipywidgets import Widget\n",
    "Widget.close_all()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmju/+Dts4LVloQYB8uCZg",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1578.360751,
   "end_time": "2025-04-10T05:34:15.314871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-10T05:07:56.954120",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
